{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UKI13fHfkEc5","executionInfo":{"status":"ok","timestamp":1742394316606,"user_tz":-330,"elapsed":36051,"user":{"displayName":"Jasna Jabin","userId":"08489398569160657763"}},"outputId":"9a1ae627-58a7-432f-be94-6433c3c4eec8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":35840,"status":"ok","timestamp":1742394378673,"user":{"displayName":"Jasna Jabin","userId":"08489398569160657763"},"user_tz":-330},"id":"oqCzd3-Cledd","outputId":"9f7ccfc0-4b44-4121-9185-5017e6c2ebc6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libgeos-dev is already the newest version (3.11.1-1~jammy0).\n","libgeos-dev set to manually installed.\n","0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n","Collecting basemap\n","  Downloading basemap-1.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (9.1 kB)\n","Collecting basemap-data<1.4,>=1.3.2 (from basemap)\n","  Downloading basemap_data-1.3.2-py2.py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: pyshp<2.4,>=1.2 in /usr/local/lib/python3.11/dist-packages (from basemap) (2.3.1)\n","Collecting matplotlib<3.9,>=1.5 (from basemap)\n","  Downloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n","Collecting pyproj<3.7.0,>=1.9.3 (from basemap)\n","  Downloading pyproj-3.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n","Collecting packaging<24.0,>=16.0 (from basemap)\n","  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n","Collecting numpy<1.27,>=1.21 (from basemap)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=1.5->basemap) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=1.5->basemap) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=1.5->basemap) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=1.5->basemap) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=1.5->basemap) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=1.5->basemap) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=1.5->basemap) (2.8.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj<3.7.0,>=1.9.3->basemap) (2025.1.31)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<3.9,>=1.5->basemap) (1.17.0)\n","Downloading basemap-1.4.1-cp311-cp311-manylinux1_x86_64.whl (942 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m942.4/942.4 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading basemap_data-1.3.2-py2.py3-none-any.whl (30.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyproj-3.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyproj, packaging, numpy, basemap-data, matplotlib, basemap\n","  Attempting uninstall: pyproj\n","    Found existing installation: pyproj 3.7.1\n","    Uninstalling pyproj-3.7.1:\n","      Successfully uninstalled pyproj-3.7.1\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.2\n","    Uninstalling packaging-24.2:\n","      Successfully uninstalled packaging-24.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.10.0\n","    Uninstalling matplotlib-3.10.0:\n","      Successfully uninstalled matplotlib-3.10.0\n","Successfully installed basemap-1.4.1 basemap-data-1.3.2 matplotlib-3.8.4 numpy-1.26.4 packaging-23.2 pyproj-3.6.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["matplotlib","mpl_toolkits"]},"id":"8f15462c99164323860f266e7bd7ac32"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting basemap-data-hires\n","  Downloading basemap_data_hires-1.3.2-py2.py3-none-any.whl.metadata (2.3 kB)\n","Downloading basemap_data_hires-1.3.2-py2.py3-none-any.whl (91.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: basemap-data-hires\n","Successfully installed basemap-data-hires-1.3.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["mpl_toolkits"]},"id":"6bdeffc645624bcda14b57a977901200"}},"metadata":{}}],"source":["%apt-get install libgeos-dev\n","%pip install basemap\n","%pip install basemap-data-hires"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":89,"status":"error","timestamp":1742394336472,"user":{"displayName":"Jasna Jabin","userId":"08489398569160657763"},"user_tz":-330},"id":"04nV5RyflNuw","colab":{"base_uri":"https://localhost:8080/","height":314},"outputId":"a1fe48ed-28d6-4a3e-a208-3402868ebf5f"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'mpl_toolkits.basemap'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-d9467465a3b6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasemap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasemap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mpl_toolkits.basemap'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from mpl_toolkits.basemap import Basemap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j6Giw-0BkC2t"},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib\n","import sklearn\n","from sklearn_pandas import DataFrameMapper\n","from functools import partial\n","matplotlib.style.use('ggplot')\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"elapsed":1341,"status":"error","timestamp":1742390887794,"user":{"displayName":"Jasna Jabin","userId":"08489398569160657763"},"user_tz":-330},"id":"a4lHqGVWkC25","outputId":"b900d79a-4cc2-4d3c-ba38-94160ed2508d"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Project/Dataset/edata.csv'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-ba1b1e4aec8c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Project/Dataset/edata.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Region'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Project/Dataset/edata.csv'"]}],"source":["df = pd.read_csv('/content/drive/MyDrive/Project/Dataset/edata.csv')\n","del df['Region']\n","df = df.iloc[::-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B3i_eGUJkC27"},"outputs":[],"source":["train_test_ratio = .8\n","train_size = int(df.shape[0] * train_test_ratio)\n","train_data = df.iloc[:train_size]\n","test_data = df.iloc[train_size:]\n","cross_val_size = test_data.shape[0]//2\n","cross_val_data = test_data.iloc[:cross_val_size]\n","test_data = test_data.iloc[cross_val_size:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftOQXKeIkC29"},"outputs":[],"source":["def plot_earthquakes(data):\n","    m = Basemap(projection='mill',llcrnrlat=9.800,urcrnrlat=37.720, llcrnrlon=64.510,urcrnrlon=107.580,resolution='c')\n","    m.drawcoastlines()\n","    m.drawcountries()\n","    m.fillcontinents(color='burlywood',lake_color='lightblue', zorder = 1)\n","    m.drawmapboundary(fill_color='lightblue')\n","    x, y= m(list(data['Lon']), list(data['Lat']))\n","    m.scatter(x, y, s = data['Mag']*data['Depth km']*0.1, marker='o', alpha=0.3, zorder=10, cmap = 'coolwarm')\n","plot_earthquakes(cross_val_data)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":172,"status":"error","timestamp":1742394325518,"user":{"displayName":"Jasna Jabin","userId":"08489398569160657763"},"user_tz":-330},"id":"5ctgPClxkC2_","colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"f6574f45-6d9f-4360-87dd-0050bc318960"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'partial' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-afdfcb2dfe97>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmagscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlatscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlonscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdepthscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'partial' is not defined"]}],"source":["scaler = partial(sklearn.preprocessing.MinMaxScaler, (-1, 1))\n","magscaler = scaler()\n","latscaler = scaler()\n","lonscaler = scaler()\n","depthscaler = scaler()\n","timescaler = scaler()\n","mapper = DataFrameMapper([\n","       # (['Region'], None),\n","        (['Mag'],magscaler),\n","        (['Lat'],latscaler),\n","        (['Lon'],lonscaler),\n","        (['Depth km'],depthscaler),\n","        (['Timestamp'], timescaler)\n","    ],default = None)\n","train_data = mapper.fit_transform(train_data)\n","#train_data[['Mag','Lat','Lon','Timestamp','Depth km']] = train_data[['Mag','Lat','Lon','Timestamp','Depth km']].astype(float)\n","test_data = mapper.transform(test_data)[:-1]\n","cross_val_data = mapper.transform(cross_val_data)\n","#test_data[['Mag','Lat','Lon','Timestamp','Depth km']] = test_data[['Mag','Lat','Lon','Timestamp','Depth km']].astype(float)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DnnTioXBkC3B"},"outputs":[],"source":["num_epochs = 3\n","truncated_backprop_length = 15\n","state_size = 10  # num hidden units\n","echo_step = -3\n","batch_size = 4 # must be a factor of train data and test data size\n","total_series_length, num_features = train_data.shape\n","num_outputs = num_features\n","num_batches = total_series_length - (total_series_length//batch_size*(batch_size-1) + truncated_backprop_length-1)\n","num_layers = 2  # num hidden layers\n","learning_rate_decay = .8\n","\n","x = train_data\n","y = np.roll(x, echo_step,axis=0)\n","y[echo_step:] = np.zeros(num_features)\n","x = x.reshape((batch_size, -1, num_features))\n","y = y.reshape((batch_size, -1, num_features))\n","\n","def prepareNoBatches(data):\n","    x = data\n","    y = np.roll(x, echo_step, 0)\n","    y[echo_step:] = np.zeros(num_features)\n","    x = np.vstack([np.expand_dims(x, 0), np.zeros((3, x.shape[0], 5))])\n","    y = np.vstack([np.expand_dims(y, 0), np.zeros((3, y.shape[0], 5))])\n","    return x, y\n","\n","xtest, ytest = prepareNoBatches(test_data)\n","xcross, ycross = prepareNoBatches(cross_val_data)\n","\n","total_series_length, _ = test_data.shape\n","num_batches_test = total_series_length - (total_series_length//batch_size*(batch_size-1) + truncated_backprop_length-1)\n","\n","graph = tf.Graph()\n","with graph.as_default():\n","\n","    batchX_placeholder = tf.placeholder(tf.float32, [batch_size, None, num_features])\n","    batchY_placeholder = tf.placeholder(tf.float32, [batch_size, None, num_features])\n","\n","    keep_prob = tf.placeholder(tf.float32)\n","    init_state = tf.placeholder(tf.float32, [num_layers, 2, batch_size, state_size])\n","\n","    state_per_layer_list = tf.unstack(init_state, axis=0)\n","    rnn_tuple_state = tuple([tf.contrib.rnn.core_rnn_cell.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n","                   for idx in range(num_layers)])\n","\n","    W = tf.Variable(np.random.rand(state_size+num_features, state_size), dtype=tf.float32)\n","    b = tf.Variable(np.zeros((1,state_size)), dtype=tf.float32)\n","\n","    W2 = tf.Variable(np.random.rand(state_size, num_outputs),dtype=tf.float32)\n","    b2 = tf.Variable(np.zeros((1,num_outputs)), dtype=tf.float32)\n","\n","    # Forward passes\n","    cell = tf.contrib.rnn.core_rnn_cell.LSTMCell(state_size, state_is_tuple=True)\n","    cell = tf.contrib.rnn.core_rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_prob)\n","    cell = tf.contrib.rnn.core_rnn_cell.MultiRNNCell([cell] * num_layers, state_is_tuple=True)\n","\n","    states_series, current_state = tf.nn.dynamic_rnn(cell, batchX_placeholder, initial_state=rnn_tuple_state)\n","    states_series = tf.reshape(states_series, [-1, state_size])\n","\n","    outputs = tf.matmul(states_series, W2) + b2\n","    targets = tf.reshape(batchY_placeholder, [-1, num_features])\n","\n","    losses = tf.sqrt(tf.reduce_mean(tf.squared_difference(outputs, targets),0))\n","    total_loss = tf.reduce_sum(losses)\n","    step = tf.Variable(0, trainable=False)\n","    learning_rate = tf.placeholder(tf.float32)\n","    train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)\n","\n","batchesX = []\n","batchesY = []\n","for batch_idx in range(num_batches):\n","    start_idx = batch_idx\n","    end_idx = start_idx + truncated_backprop_length\n","\n","    batchesX.append(x[:, start_idx:end_idx])\n","    batchesY.append(y[:, start_idx:end_idx])\n","\n","loss_list = []\n","lr = 1\n","test_outputs = None\n","test_targets = None\n","cross_outputs = None\n","cross_targets = None\n","with tf.Session(graph=graph) as sess:\n","    tf.global_variables_initializer().run()\n","    print('Training set loss:')\n","    for epoch_idx in range(num_epochs):\n","\n","        _current_state = np.zeros((num_layers, 2, batch_size, state_size))\n","        batch_loss = []\n","        for batch_idx in range(num_batches):\n","\n","            _total_loss, _train_step, _current_state = sess.run(\n","                [total_loss, train_step, current_state],\n","                feed_dict={\n","                    batchX_placeholder: batchesX[batch_idx],\n","                    batchY_placeholder: batchesY[batch_idx],\n","                    init_state: _current_state,\n","                    keep_prob: 0.8,\n","                    learning_rate: lr\n","                })\n","            batch_loss.append(_total_loss)\n","\n","        loss_list.append(np.mean(batch_loss))\n","        if np.argmin(loss_list[-2:]) == 0:\n","            lr *= learning_rate_decay\n","            print('lr decreased to', lr)\n","        if lr < .00001:\n","            num_epochs = epoch_idx + 1\n","            break\n","        if epoch_idx % 1 == 0:\n","            print(\"Epoch\", epoch_idx, \"avg. batch loss\", np.mean(batch_loss))\n","\n","    _current_state = np.zeros((num_layers, 2, batch_size, state_size))\n","\n","    _total_loss, indv_losses, cross_outputs, cross_targets = sess.run(\n","        [total_loss, losses, outputs, targets],\n","        feed_dict={\n","            batchX_placeholder: xcross,\n","            batchY_placeholder: ycross,\n","            init_state: _current_state,\n","            keep_prob: 1\n","        })\n","    #print('Cross val loss:', _total_loss)\n","\n","plt.plot(loss_list,label='Total loss')\n","plt.plot(loss_list, color='black', label='Smoothened')\n","plt.ylabel('loss')\n","plt.xlabel('epochs')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3O5fFn9OkC3E"},"outputs":[],"source":["#test_targets = np.reshape(test_targets, (num_batches_test,batch_size,truncated_backprop_length,num_features))\n","#test_outputs = np.reshape(test_outputs, (num_batches_test,batch_size,truncated_backprop_length,num_features))\n","#test_t = np.zeros((num_batches_test, batch_size, num_features))\n","#test_o = np.zeros((num_batches_test, batch_size, num_features))\n","#for i in range(test_targets.shape[0]):\n","    #test_t[i] = test_targets[i, :, -1, :]\n","    #test_o[i] = test_outputs[i, :, -1, :]\n","#test_t = test_t.reshape((-1, 5))\n","#test_o = test_o.reshape((-1, 5))\n","#from sklearn.metrics import r2_score\n","#total_error = r2_score(test_t, test_o)\n","#print(\"total r2 score\", total_error)\n","#plt.axhline([total_error],0,1,label='overall score')\n","#indv_error_dict = {col:np.round(r2_score(test_t[:,i], test_o[:,i]),3) for i, col in enumerate(df.columns)}\n","#print(\"r2 scores for individual variables\", indv_error_dict)\n","#plt.bar(range(len(indv_error_dict)), indv_error_dict.values())\n","#plt.xticks(range(len(indv_error_dict)), indv_error_dict.keys())\n","#plt.ylabel('r2 score')\n","#plt.xlabel('Predicted Variable')\n","#plt.legend()\n","#plt.savefig(\"test.eps\", format=\"eps\")\n","#plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"931tXLxtkC3G"},"outputs":[],"source":["#test_outputs = np.zeros((420,5))\n","#for i in range(10):\n","    #test_outputs += np.load(str(i) + '_results.bin.npy')\n","#test_outputs /= 10\n","#test_targets = np.load('targets.bin.npy')\n","#from sklearn.metrics import r2_score\n","#total_error = r2_score(test_targets, test_outputs)\n","#print(\"total r2 score\", total_error)\n","#plt.axhline([total_error],0,1,label='overall score')\n","#indv_error_dict = {col:np.round(r2_score(test_targets[:,i], test_outputs[:,i]),3) for i, col in enumerate(df.columns)}\n","#print(\"r2 scores for individual variables\", indv_error_dict)\n","#plt.bar(range(len(indv_error_dict)), indv_error_dict.values())\n","#plt.xticks(range(len(indv_error_dict)), indv_error_dict.keys())\n","#plt.ylabel('r2 score')\n","#plt.xlabel('Predicted Variable')\n","#plt.legend()\n","#plt.savefig(\"test.eps\", format=\"eps\")\n","#plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXooj8u1kC3I"},"outputs":[],"source":["t, o = cross_targets.reshape((4,-1,5))[0], cross_outputs.reshape((4,-1,5))[0]\n","print('Cross val score', r2_score(t, o))\n","res = {}\n","res['Mag'] = magscaler.inverse_transform(t[:,0])\n","res['Lat'] = latscaler.inverse_transform(t[:,1])\n","res['Lon'] = lonscaler.inverse_transform(t[:,2])\n","res['Depth km'] = depthscaler.inverse_transform(t[:,3])\n","res['Timestamp'] = timescaler.inverse_transform(t[:,4])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYlTckl4kC3J"},"outputs":[],"source":["plot_earthquakes(res)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MPgwausqkC3K"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"sarcoma","name":"sarcoma"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.3"},"name":"lstm.ipynb"},"nbformat":4,"nbformat_minor":0}